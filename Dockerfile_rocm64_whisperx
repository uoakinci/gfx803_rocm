# Docker Buildfile for ROCm 6.4 for Whisper-WebUI/whisperX/CTranslate2-rocm 
# use a RX5(x)0 / Polaris / gfx803 AMD GPU with ROCm 6.4
# created, build and compiled by Robert Rosenbusch at December 2024 / May 2025

### Build rocm64_gfx803_base:6.4 first! Read the README.md, it could save lifetime :P
FROM rocm64_gfx803_pytorch:2.6

SHELL ["/bin/bash", "-c"]  
ENV WHISPERX_GUI_PORT=7860 \
    DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONENCODING==UTF-8 \
    REQS_FILE='requirements.txt' \
    COMMANDLINE_ARGS='' \
    PIP_ROOT_USER_ACTION='ignore' \
    ### For your AMD GPU
    PYTORCH_ROCM_ARCH=gfx803 
    
##### Prepare Conda for CTranslate-for-ROCm
## Install miniconda for WhisperX
WORKDIR /
RUN wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh &&\
    /bin/bash /tmp/miniconda.sh -b -p /opt/conda && \
    rm /tmp/miniconda.sh && \
    echo "export PATH=/opt/conda/bin:$PATH" > /etc/profile.d/conda.sh &&\
    echo PATH=/opt/conda/bin:$PATH >> /etc/environment && \
    export PATH=/opt/conda/bin:$PATH &&\
    true

RUN /opt/conda/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main \
 && /opt/conda/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r

RUN /opt/conda/bin/conda update -n base -c defaults conda &&\
    /opt/conda/bin/conda create -n py_3.12 python=3.12 &&\    
    /opt/conda/bin/conda init &&\
    true 

SHELL ["/opt/conda/bin/conda", "run", "--no-capture-output", "-n", "py_3.12", "/bin/bash", "-c"]    

### Install libc++ Conda-Libs to compile CTranslate-for-rocm
RUN /opt/conda/bin/conda install -y -c conda-forge libstdcxx-ng=12 &&\
    /opt/conda/bin/conda install -y -c conda-forge libstdcxx-ng=13 &&\
    true

### Checkout and Prepare CTranslate-for-ROCm
RUN git clone https://github.com/arlo-phoenix/CTranslate2-rocm.git --recurse-submodules /CTranslate2-rocm && \
    true 

### Compile and build WHL CTranslate-for-ROCm
WORKDIR /CTranslate2-rocm
RUN CLANG_CMAKE_CXX_COMPILER=amdclang++ CXX=amdclang++ HIPCXX="$(hipconfig -l)/clang" HIP_PATH="$(hipconfig -R)" cmake -S . -B build -DWITH_MKL=OFF -DWITH_HIP=ON -DCMAKE_HIP_ARCHITECTURES=$PYTORCH_ROCM_ARCH -DBUILD_TESTS=ON -DWITH_CUDNN=ON &&\
    cmake --build build -- -j $MAX_JOBS &&\
    cd build &&\
    true 

WORKDIR /CTranslate2-rocm/build
RUN cmake --install . --prefix $CONDA_PREFIX && \
    ldconfig &&\
    true

WORKDIR /CTranslate2-rocm/python
RUN pip install -r install_requirements.txt &&\
    python3 setup.py bdist_wheel &&\
    LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/ &&\
    pip install dist/*.whl &&\
    echo LD_LIBRARY_PATH=$LD_LIBRARY_PATH >> /etc/environment && \
    true

## Checkout Whisper-WebUI       
WORKDIR /     
RUN git clone https://github.com/jhj0517/Whisper-WebUI.git &&\
    true

### Install Whisper-WebUI and reinstall all necesarry WHL into the Python Environment    
WORKDIR /Whisper-WebUI
RUN python3 -m venv venv && \
    ./venv/bin/python3 -m pip install --upgrade pip && \
    ./venv/bin/pip install -r requirements.txt && \
    ./venv/bin/pip install gradio gradio_i18n &&\
    ./venv/bin/pip install whisperx &&\
    ./venv/bin/pip uninstall -y torch torchvision torchaudio && \    
    ./venv/bin/pip install /pytorch/dist/*.whl && \
    ./venv/bin/pip install /vision/dist/*.whl && \
    ./venv/bin/pip install /audio/dist/*.whl && \
    ./venv/bin/pip install --force-reinstall  /CTranslate2-rocm/python/dist/*.whl &&\    
    ./venv/bin/python3 -m pip uninstall numpy -y && \
    ./venv/bin/pip install numpy==1.26.4 &&\
    true    

### Create a best practice Shell Script to start WhisperX
RUN touch whisp.sh && \
    echo "#!/bin/bash" > whisp.sh && \
    echo "./venv/bin/python3 app.py --whisper_type faster-whisper --share --server_name 0.0.0.0 --server_port ${WHISPERX_GUI_PORT}" >> whisp.sh && \
    chmod +x whisp.sh && \
    true    

EXPOSE ${WHISPERX_GUI_PORT}
CMD ["bash", "/Whisper-WebUI/whisp.sh"]
